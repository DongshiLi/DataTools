{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYSQL_HOST = \n",
    "MYSQL_USER = \n",
    "MYSQL_PASSWORD = \n",
    "MYSQL_CHARSET = \n",
    "wind = create_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_logger(log_file=None, level=logging.DEBUG, mode='a', name=\"\"):\n",
    "    \"\"\"\n",
    "    written by Sha\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    formatter = logging.Formatter(fmt='[%(asctime)s] %(levelname)s: %(module)s: %(message)s')\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "    logger.addHandler(handler)\n",
    "    if log_file is not None:\n",
    "        handler_file = logging.FileHandler(filename=log_file, encoding='utf-8', mode=mode)\n",
    "        handler_file.setFormatter(formatter)\n",
    "        logger.addHandler(handler_file)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(logger, content):\n",
    "    if logger is not None:\n",
    "        logger.info(content)\n",
    "    else:\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_date(start_date):\n",
    "    \"\"\"\n",
    "    :param start_date: could be none\n",
    "    :return: [(s, e), (s, e), (s, None)]\n",
    "    \"\"\"\n",
    "    if start_date is None:\n",
    "        return [(None, None)]\n",
    "    start_dt = datetime.strptime(str(start_date), '%Y%m%d')\n",
    "    today = datetime.today()\n",
    "    periods = []\n",
    "    _start = start_dt\n",
    "    _end = datetime(start_dt.year, 12, 31)\n",
    "    for i in range(100):\n",
    "        if _end.date() < today.date():\n",
    "            periods.append((int(_start.strftime('%Y%m%d')), int(_end.strftime('%Y%m%d'))))\n",
    "        else:\n",
    "            periods.append((int(_start.strftime('%Y%m%d')), int(today.strftime(\"%Y%m%d\"))))\n",
    "            break\n",
    "        _temp = _end + relativedelta(days=1)\n",
    "        _end = _end + relativedelta(years=1)\n",
    "        _start = _temp\n",
    "    return periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_info_sql = \"SELECT * FROM ASHAREDESCRIPTION WHERE S_INFO_WINDCODE NOT LIKE 'A%'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECT_ID</th>\n",
       "      <th>S_INFO_WINDCODE</th>\n",
       "      <th>S_INFO_CODE</th>\n",
       "      <th>S_INFO_NAME</th>\n",
       "      <th>S_INFO_COMPNAME</th>\n",
       "      <th>S_INFO_COMPNAMEENG</th>\n",
       "      <th>S_INFO_ISINCODE</th>\n",
       "      <th>S_INFO_EXCHMARKET</th>\n",
       "      <th>S_INFO_LISTBOARD</th>\n",
       "      <th>S_INFO_LISTDATE</th>\n",
       "      <th>S_INFO_DELISTDATE</th>\n",
       "      <th>S_INFO_SEDOLCODE</th>\n",
       "      <th>CRNCY_CODE</th>\n",
       "      <th>S_INFO_PINYIN</th>\n",
       "      <th>S_INFO_LISTBOARDNAME</th>\n",
       "      <th>IS_SHSC</th>\n",
       "      <th>S_INFO_COMPCODE</th>\n",
       "      <th>OPDATE</th>\n",
       "      <th>OPMODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{0000B5D4-B786-4B03-A7B0-50E3767ABF84}</td>\n",
       "      <td>600373.SH</td>\n",
       "      <td>600373</td>\n",
       "      <td>中文传媒</td>\n",
       "      <td>中文天地出版传媒集团股份有限公司</td>\n",
       "      <td>Chinese Universe Publishing and Media Group Co...</td>\n",
       "      <td>CNE0000019X4</td>\n",
       "      <td>SSE</td>\n",
       "      <td>434004000</td>\n",
       "      <td>20020304</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CNY</td>\n",
       "      <td>zwcm</td>\n",
       "      <td>主板</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1600373</td>\n",
       "      <td>2015-09-09 09:07:23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{001EE265-3F28-DD72-E050-C80A100105DE}</td>\n",
       "      <td>300557.SZ</td>\n",
       "      <td>300557</td>\n",
       "      <td>理工光科</td>\n",
       "      <td>武汉理工光科股份有限公司</td>\n",
       "      <td>Wuhan Ligong Guangke Co.Ltd.</td>\n",
       "      <td>CNE100002DC1</td>\n",
       "      <td>SZSE</td>\n",
       "      <td>434001000</td>\n",
       "      <td>20161101</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CNY</td>\n",
       "      <td>lggk</td>\n",
       "      <td>创业板</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1uF6BE2FE5</td>\n",
       "      <td>2017-01-05 15:26:58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{0058F562-B872-4558-A53B-313201BF5C86}</td>\n",
       "      <td>000416.SZ</td>\n",
       "      <td>000416</td>\n",
       "      <td>民生控股</td>\n",
       "      <td>民生控股股份有限公司</td>\n",
       "      <td>Minsheng Holdings Co.,Ltd</td>\n",
       "      <td>CNE0000009P1</td>\n",
       "      <td>SZSE</td>\n",
       "      <td>434004000</td>\n",
       "      <td>19960719</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CNY</td>\n",
       "      <td>mskg</td>\n",
       "      <td>主板</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000416</td>\n",
       "      <td>2015-09-09 09:08:04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{00910667-25C7-429A-AF39-515A56E11D9E}</td>\n",
       "      <td>002156.SZ</td>\n",
       "      <td>002156</td>\n",
       "      <td>通富微电</td>\n",
       "      <td>通富微电子股份有限公司</td>\n",
       "      <td>TongFu Microelectronics Co.,Ltd.</td>\n",
       "      <td>CNE1000006C3</td>\n",
       "      <td>SZSE</td>\n",
       "      <td>434003000</td>\n",
       "      <td>20070816</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CNY</td>\n",
       "      <td>tfwd</td>\n",
       "      <td>中小企业板</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2o557A92BF</td>\n",
       "      <td>2017-03-20 00:22:43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{00A97A43-6466-41D6-B7B7-017B6868D630}</td>\n",
       "      <td>600500.SH</td>\n",
       "      <td>600500</td>\n",
       "      <td>中化国际</td>\n",
       "      <td>中化国际(控股)股份有限公司</td>\n",
       "      <td>Sinochem International Corporation</td>\n",
       "      <td>CNE0000011R3</td>\n",
       "      <td>SSE</td>\n",
       "      <td>434004000</td>\n",
       "      <td>20000301</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CNY</td>\n",
       "      <td>zhgj</td>\n",
       "      <td>主板</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1600500</td>\n",
       "      <td>2015-09-09 09:08:19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                OBJECT_ID S_INFO_WINDCODE S_INFO_CODE  \\\n",
       "0  {0000B5D4-B786-4B03-A7B0-50E3767ABF84}       600373.SH      600373   \n",
       "1  {001EE265-3F28-DD72-E050-C80A100105DE}       300557.SZ      300557   \n",
       "2  {0058F562-B872-4558-A53B-313201BF5C86}       000416.SZ      000416   \n",
       "3  {00910667-25C7-429A-AF39-515A56E11D9E}       002156.SZ      002156   \n",
       "4  {00A97A43-6466-41D6-B7B7-017B6868D630}       600500.SH      600500   \n",
       "\n",
       "  S_INFO_NAME   S_INFO_COMPNAME  \\\n",
       "0        中文传媒  中文天地出版传媒集团股份有限公司   \n",
       "1        理工光科      武汉理工光科股份有限公司   \n",
       "2        民生控股        民生控股股份有限公司   \n",
       "3        通富微电       通富微电子股份有限公司   \n",
       "4        中化国际    中化国际(控股)股份有限公司   \n",
       "\n",
       "                                  S_INFO_COMPNAMEENG S_INFO_ISINCODE  \\\n",
       "0  Chinese Universe Publishing and Media Group Co...    CNE0000019X4   \n",
       "1                       Wuhan Ligong Guangke Co.Ltd.    CNE100002DC1   \n",
       "2                          Minsheng Holdings Co.,Ltd    CNE0000009P1   \n",
       "3                   TongFu Microelectronics Co.,Ltd.    CNE1000006C3   \n",
       "4                 Sinochem International Corporation    CNE0000011R3   \n",
       "\n",
       "  S_INFO_EXCHMARKET S_INFO_LISTBOARD S_INFO_LISTDATE S_INFO_DELISTDATE  \\\n",
       "0               SSE        434004000        20020304              None   \n",
       "1              SZSE        434001000        20161101              None   \n",
       "2              SZSE        434004000        19960719              None   \n",
       "3              SZSE        434003000        20070816              None   \n",
       "4               SSE        434004000        20000301              None   \n",
       "\n",
       "  S_INFO_SEDOLCODE CRNCY_CODE S_INFO_PINYIN S_INFO_LISTBOARDNAME  IS_SHSC  \\\n",
       "0             None        CNY          zwcm                   主板      1.0   \n",
       "1             None        CNY          lggk                  创业板      0.0   \n",
       "2             None        CNY          mskg                   主板      0.0   \n",
       "3             None        CNY          tfwd                中小企业板      2.0   \n",
       "4             None        CNY          zhgj                   主板      1.0   \n",
       "\n",
       "  S_INFO_COMPCODE              OPDATE OPMODE  \n",
       "0         1600373 2015-09-09 09:07:23      0  \n",
       "1      1uF6BE2FE5 2017-01-05 15:26:58      0  \n",
       "2         1000416 2015-09-09 09:08:04      0  \n",
       "3      2o557A92BF 2017-03-20 00:22:43      0  \n",
       "4         1600500 2015-09-09 09:08:19      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock_info = pd.read_sql_query(stock_info_sql, wind)\n",
    "df_stock_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SuperTable(start_date=20060101, end_date=None):\n",
    "    SuperTable_sql = \"SELECT *\" + \\\n",
    "                     \" FROM ASHARESUPERTABLE\" + \\\n",
    "                     \" WHERE TRADE_DT > '\" + str(start_date) + \\\n",
    "                     \"' AND TRADE_DT <= '\" + str(end_date) + \\\n",
    "                     \"' ORDER BY TRADE_DT\"\n",
    "    df = pd.read_sql_query(SuperTable_sql, wind)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DataDate(start_date=20060101, end_date=None):\n",
    "    DataDate_sql = \"SELECT *\" + \\\n",
    "                \" FROM ASHARECALENDAR\" + \\\n",
    "                \" WHERE S_INFO_EXCHMARKET = 'SSE' AND TRADE_DAYS > '\" + str(start_date) + \\\n",
    "                \"' AND TRADE_DAYS <= '\" + str(end_date) + \\\n",
    "                \"' ORDER BY TRADE_DAYS\"\n",
    "    df = pd.read_sql_query(DataDate_sql, wind)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class datachecking:\n",
    "    \n",
    "    def __init__(self,data_df,stock_info,DataDate,logger,start_date=20060101,end_date=None):\n",
    "        '''\n",
    "        data_df :\n",
    "            index  : sid DataDate (ticktime)\n",
    "            columns: price,derivatives,INDUSTRY,UNIVERSE,ST,.....\n",
    "            \n",
    "        stock_info : sid,list_date,delist_date\n",
    "        DataDate   : trading calendar    \n",
    "        '''\n",
    "        self.data_df = data_df\n",
    "        self.stock_info = stock_info\n",
    "        self.DataDate = DataDate\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.logger = logger\n",
    "        pass\n",
    "    \n",
    "    def check_abvalue(self):\n",
    "        '''\n",
    "        inf,nan,price==0\n",
    "        '''\n",
    "        if(self.data_df.empty == True):\n",
    "            pass\n",
    "        else:\n",
    "            for sid, data in self.data_df.groupby(level = 'S_INFO_WINDCODE'):\n",
    "                print(sid + \"check abvalue\")\n",
    "                for i in range(len(data)):\n",
    "                    for j in range(len(data.columns)):\n",
    "                        if((data.iloc[i, j] == None)):\n",
    "                            print(str(data.index[i]) + \" \" + data.columns[j] + \"does not have data\")\n",
    "                            write_log(self.logger, str(data.index[i]) + \" \" + data.columns[j] + \"does not have data\")\n",
    "                        elif((data.iloc[i, j] > 1e15) | (data.iloc[i, j] < -1e15)):\n",
    "                            print(str(data.index[i]) + \" \" + data.columns[j] + \" have infinity data\")\n",
    "                            write_log(self.logger, str(data.index[i]) + \" \" + data.columns[j] + \" have infinity data\")\n",
    "                        elif((data.iloc[i, j] == 0) & (re.search('S_DQ', data.columns[j]) != None)):\n",
    "                            print(str(data.index[i]) + \" \" + data.columns[j] + \" have zero data\")\n",
    "                            write_log(self.logger, str(data.index[i]) + \" \" + data.columns[j] + \" have zero data\")\n",
    "                        else:\n",
    "                            pass\n",
    "                    \n",
    "        \n",
    "        for i in range(len(self.stock_info)):\n",
    "            if(self.stock_info.loc[i, 'S_INFO_LISTDATE'] == None):\n",
    "                print(\"processing \" + self.stock_info.loc[i, 'S_INFO_WINDCODE'] + \" does not have list date\")\n",
    "                write_log(self.logger, self.stock_info.loc[i, 'S_INFO_WINDCODE'] + \" does not have list date\")\n",
    "            else:\n",
    "                pass\n",
    "        pass\n",
    "    \n",
    "    def check_datadate(self):\n",
    "        '''\n",
    "        unique DataDate from data_df match the trading calendar during start_date and end_date\n",
    "        '''\n",
    "        print(\"check data date\")\n",
    "        if(self.data_df.empty == True):\n",
    "            pass\n",
    "        else:\n",
    "            new_df = self.data_df.reset_index()\n",
    "            st = set(new_df['TRADE_DT'])\n",
    "            result = [self.DataDate.loc[i, 'TRADE_DAYS'] for i, e in enumerate(self.DataDate['TRADE_DAYS']) if e not in st]\n",
    "            if result:\n",
    "                print(\"Stock trade days cannot match trade calendar \" + str(result))\n",
    "                write_log(self.logger,\"Stock trade days cannot match trade calendar \" + str(result))\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def check_idx_unique(self):\n",
    "        '''\n",
    "        columns name unique\n",
    "        sid DataDate (tiktime) unique\n",
    "        '''\n",
    "        print(\"check idx unique\")\n",
    "        if(self.data_df.empty == True):\n",
    "            pass\n",
    "        else:\n",
    "            for i in range(len(self.data_df)):\n",
    "                if(self.data_df.index.duplicated()[i] == True):\n",
    "                    print(str(self.data_df.index[i]) + \" have duplicate sid and DataDate\")\n",
    "                    write_log(self.logger, str(self.data_df.index[i]) + \" have duplicate sid and DataDate\")\n",
    "            for j in range(len(self.data_df.columns)):\n",
    "                if(self.data_df.columns.duplicated()[j] == True):\n",
    "                    print(str(self.data_df.columns[j]) + \" have duplicate sid and DataDate\")\n",
    "                    write_log(self.logger, str(self.data_df.columns[j]) + \" have duplicate sid and DataDate\")\n",
    "        pass\n",
    "    \n",
    "    def check_listed_range(self):\n",
    "        '''\n",
    "        for DataDate range of each sid\n",
    "        max(DataDate)<delist_date\n",
    "        min(DataDate)>list_date or start_date\n",
    "        '''\n",
    "        if(self.data_df.empty == True):\n",
    "            pass\n",
    "        else:\n",
    "            for sid, data in self.data_df.groupby(level = 'S_INFO_WINDCODE'):\n",
    "                print(sid + \"check listed range\")\n",
    "                ListDate = self.stock_info.loc[self.stock_info['S_INFO_WINDCODE'] == sid, 'S_INFO_LISTDATE'].values\n",
    "                DelistDate = self.stock_info.loc[self.stock_info['S_INFO_WINDCODE'] == sid, 'S_INFO_DELISTDATE'].values\n",
    "                list_ = []\n",
    "                for i in range(len(data)):\n",
    "                    list_.append(data.iloc[:, 1].index[i][1])\n",
    "                MaxDate = max(list_)\n",
    "                MinDate = min(list_)\n",
    "                if(int(MinDate) < int(ListDate)):\n",
    "                    print(sid + \" have earlier trade days \" + MinDate + \" earlier than list date \" + ListDate)\n",
    "                    write_log(self.logger, sid + \" have earlier trade days \" + MinDate + \" earlier than list date \" + ListDate)\n",
    "                \n",
    "                elif(DelistDate == None):\n",
    "                    pass\n",
    "                \n",
    "                elif((int(MaxDate) > int(DelistDate)) & (DelistDate != None)):\n",
    "                    print(sid + \" have later trade days \" + MaxDate + \" later than delist date \" + DelistDate)\n",
    "                    write_log(self.logger, sid + \" have later trade days \" + MaxDate + \" later than delist date \" + DelistDate)\n",
    "                    \n",
    "        pass\n",
    "    \n",
    "    def check_sid_tidx(self):\n",
    "        '''\n",
    "        listed stock should have data at each DataDate (ticktime)\n",
    "        '''\n",
    "        if(self.data_df.empty == True):\n",
    "            pass\n",
    "        else:\n",
    "            for sid, data in self.data_df.groupby(level = 'S_INFO_WINDCODE'):\n",
    "                print(sid + \"check sid tidx\")\n",
    "                list_ = []\n",
    "                for i in range(len(data)):\n",
    "                    list_.append(data.iloc[:, 1].index[i][1])\n",
    "                st = set(list_)\n",
    "                ListDate = self.stock_info.loc[self.stock_info['S_INFO_WINDCODE'] == sid, 'S_INFO_LISTDATE'].values\n",
    "                DelistDate = self.stock_info.loc[self.stock_info['S_INFO_WINDCODE'] == sid, 'S_INFO_DELISTDATE'].values\n",
    "                if(DelistDate == None):\n",
    "                    condition = self.DataDate['TRADE_DAYS'].apply(lambda x: int(x) >= int(ListDate))\n",
    "                elif(DelistDate != None):\n",
    "                    condition = self.DataDate['TRADE_DAYS'].apply(lambda x: (int(x) >= int(ListDate)) & (int(x) < int(DelistDate)))\n",
    "                new_DataDate = self.DataDate.loc[condition]\n",
    "                result = [new_DataDate.loc[i, 'TRADE_DAYS'] for i, e in enumerate(new_DataDate['TRADE_DAYS']) if e not in st]\n",
    "                if result:\n",
    "                    print(sid + \" did not trade on \" + str(result))\n",
    "                    write_log(self.logger, sid + \" did not trade on \" + str(result))\n",
    "        pass\n",
    "    \n",
    "    def check_price(self):\n",
    "        '''\n",
    "        (adj)low <=...<=adj(high)\n",
    "        '''\n",
    "        if(self.data_df.empty == True):\n",
    "            pass\n",
    "        else:\n",
    "            print(\"check price\")\n",
    "            LOW_HIGH = self.data_df.loc[self.data_df['S_DQ_LOW'] >  self.data_df['S_DQ_HIGH'],].index\n",
    "            LOW_OPEN = self.data_df.loc[self.data_df['S_DQ_LOW'] >  self.data_df['S_DQ_OPEN'],].index\n",
    "            LOW_CLOSE = self.data_df.loc[self.data_df['S_DQ_LOW'] >  self.data_df['S_DQ_CLOSE'],].index\n",
    "            OPEN_HIGH = self.data_df.loc[self.data_df['S_DQ_OPEN'] >  self.data_df['S_DQ_HIGH'],].index\n",
    "            CLOSE_HIGH = self.data_df.loc[self.data_df['S_DQ_CLOSE'] >  self.data_df['S_DQ_HIGH'],].index\n",
    "            ADJLOW_ADJHIGH = self.data_df.loc[self.data_df['S_DQ_ADJLOW'] >  self.data_df['S_DQ_ADJHIGH'],].index\n",
    "            ADJLOW_ADJOPEN = self.data_df.loc[self.data_df['S_DQ_ADJLOW'] >  self.data_df['S_DQ_ADJOPEN'],].index\n",
    "            ADJLOW_ADJCLOSE = self.data_df.loc[self.data_df['S_DQ_ADJLOW'] >  self.data_df['S_DQ_ADJCLOSE'],].index\n",
    "            ADJOPEN_ADJHIGH = self.data_df.loc[self.data_df['S_DQ_ADJOPEN'] >  self.data_df['S_DQ_ADJHIGH'],].index\n",
    "            ADJCLOSE_ADJHIGH = self.data_df.loc[self.data_df['S_DQ_ADJCLOSE'] >  self.data_df['S_DQ_ADJHIGH'],].index\n",
    "            if ((len(LOW_HIGH)==0) &(len(LOW_OPEN)==0) & (len(LOW_CLOSE)==0) & (len(OPEN_HIGH)==0) & \n",
    "                (len(ADJLOW_ADJHIGH)==0) & (len(CLOSE_HIGH)==0) & (len(ADJLOW_ADJOPEN)==0) & \n",
    "                (len(ADJLOW_ADJCLOSE)==0) & (len(ADJOPEN_ADJHIGH)==0) & (len(ADJCLOSE_ADJHIGH)==0)):\n",
    "                pass\n",
    "            else:\n",
    "                WrongPrice = []\n",
    "                for i in range(len(LOW_HIGH)): WrongPrice.append(LOW_HIGH[i])\n",
    "                for i in range(len(LOW_OPEN)): WrongPrice.append(LOW_OPEN[i])\n",
    "                for i in range(len(LOW_CLOSE)): WrongPrice.append(LOW_CLOSE[i])\n",
    "                for i in range(len(OPEN_HIGH)): WrongPrice.append(OPEN_HIGH[i])\n",
    "                for i in range(len(CLOSE_HIGH)): WrongPrice.append(CLOSE_HIGH[i])\n",
    "                for i in range(len(ADJLOW_ADJHIGH)): WrongPrice.append(ADJLOW_ADJHIGH[i])\n",
    "                for i in range(len(ADJLOW_ADJOPEN)): WrongPrice.append(ADJLOW_ADJOPEN[i])\n",
    "                for i in range(len(ADJLOW_ADJCLOSE)): WrongPrice.append(ADJLOW_ADJCLOSE[i])\n",
    "                for i in range(len(ADJOPEN_ADJHIGH)): WrongPrice.append(ADJOPEN_ADJHIGH[i])\n",
    "                for i in range(len(ADJCLOSE_ADJHIGH)): WrongPrice.append(ADJCLOSE_ADJHIGH[i])\n",
    "                print(str(WrongPrice) + \" have wrong price\")\n",
    "                write_log(self.logger, str(WrongPrice) + \" have wrong price\")\n",
    "        pass\n",
    "        '''\n",
    "        else:\n",
    "            for sid, data in self.data_df.groupby(level = 'S_INFO_WINDCODE'):\n",
    "                print(sid + \"check price\")\n",
    "                for i in range(len(data)):\n",
    "                    Low = data.iloc[i]['S_DQ_LOW']\n",
    "                    Open = data.iloc[i]['S_DQ_OPEN']\n",
    "                    High = data.iloc[i]['S_DQ_HIGH']\n",
    "                    Close = data.iloc[i]['S_DQ_CLOSE']\n",
    "                    AdjLow = data.iloc[i]['S_DQ_ADJLOW']\n",
    "                    AdjOpen = data.iloc[i]['S_DQ_ADJOPEN']\n",
    "                    AdjHigh = data.iloc[i]['S_DQ_ADJHIGH']\n",
    "                    AdjClose = data.iloc[i]['S_DQ_ADJCLOSE']\n",
    "                    if((Low <= High) & (Low <= Open) & (Low <= Close) & (Open <= High) & (Close <= High) & \n",
    "                       (AdjLow <= AdjHigh) & (AdjLow <= AdjOpen) & (AdjLow <= AdjClose) & (AdjOpen <= AdjHigh) & (AdjClose <= AdjHigh)):\n",
    "                        pass\n",
    "                    else:\n",
    "                        print(str(data.index[i]) + \" have wrong price\")\n",
    "                        write_log(self.logger, str(data.index[i]) + \" have wrong price\")\n",
    "        \n",
    "        pass\n",
    "        '''\n",
    "        \n",
    "        \n",
    "      \n",
    "    def check_volume(self):\n",
    "        '''\n",
    "        if volume==0:\n",
    "            ret==0\n",
    "            open==high==low==close==pre_close, same for adj price\n",
    "        '''\n",
    "        if(self.data_df.empty == True):\n",
    "            pass\n",
    "        else:\n",
    "            print(\"check volume\")\n",
    "            volume_list = df.loc[df['S_VOLUME'] ==0,]\n",
    "            open_low = volume_list.loc[volume_list['S_DQ_LOW']!=volume_list['S_DQ_OPEN'],].index\n",
    "            open_high = volume_list.loc[volume_list['S_DQ_HIGH']!=volume_list['S_DQ_OPEN'],].index\n",
    "            open_close =  volume_list.loc[volume_list['S_DQ_OPEN']!=volume_list['S_DQ_CLOSE'],].index  \n",
    "            open_pre = volume_list.loc[volume_list['S_DQ_OPEN']!=volume_list['S_DQ_PRECLOSE'],].index\n",
    "            high_low = volume_list.loc[volume_list['S_DQ_HIGH']!=volume_list['S_DQ_LOW'],].index\n",
    "            high_close =  volume_list.loc[volume_list['S_DQ_HIGH']!=volume_list['S_DQ_CLOSE'],].index \n",
    "            high_pre = volume_list.loc[volume_list['S_DQ_HIGH']!=volume_list['S_DQ_PRECLOSE'],].index\n",
    "            low_pre = volume_list.loc[volume_list['S_DQ_LOW']!=volume_list['S_DQ_PRECLOSE'],].index\n",
    "            low_close =  volume_list.loc[volume_list['S_DQ_LOW']!=volume_list['S_DQ_CLOSE'],].index \n",
    "            close_pre =  volume_list.loc[volume_list['S_DQ_PRECLOSE']!=volume_list['S_DQ_CLOSE'],].index \n",
    "\n",
    "            adj_open_low = volume_list.loc[volume_list['S_DQ_ADJLOW']!=volume_list['S_DQ_ADJOPEN'],].index\n",
    "            adj_open_high = volume_list.loc[volume_list['S_DQ_ADJHIGH']!=volume_list['S_DQ_ADJOPEN'],].index\n",
    "            adj_open_close =  volume_list.loc[volume_list['S_DQ_ADJOPEN']!=volume_list['S_DQ_ADJCLOSE'],].index  \n",
    "            adj_high_low = volume_list.loc[volume_list['S_DQ_ADJHIGH']!=volume_list['S_DQ_ADJLOW'],].index\n",
    "            adj_high_close =  volume_list.loc[volume_list['S_DQ_ADJHIGH']!=volume_list['S_DQ_ADJCLOSE'],].index \n",
    "            adj_low_close =  volume_list.loc[volume_list['S_DQ_ADJLOW']!=volume_list['S_DQ_ADJCLOSE'],].index \n",
    "\n",
    "            if (len(open_low)==0 & len(open_high)==0 & len(open_close)==0 & len(open_pre)==0 & \n",
    "                len(high_low==0) & len(high_close)==0 & len(high_pre==0) & len(low_pre)==0 & \n",
    "                len(low_close)==0 &len(close_pre)==0 & len(adj_open_low)==0 & len(adj_open_high)==0 &\n",
    "                len(adj_open_close)==0 & len(adj_high_low)==0 & len(adj_high_close) == 0 & len(adj_low_close) ==0):\n",
    "                pass\n",
    "            else:\n",
    "                WrongVolume = []\n",
    "                for i in range(len(open_low)): WrongVolume.append(open_low[i])\n",
    "                for i in range(len(open_high)): WrongVolume.append(open_high[i])\n",
    "                for i in range(len(open_close)): WrongVolume.append(open_close[i])\n",
    "                for i in range(len(open_pre)): WrongVolume.append(open_pre[i])\n",
    "                for i in range(len(high_low)): WrongVolume.append(high_low[i])\n",
    "                for i in range(len(high_close)): WrongVolume.append(high_close[i])\n",
    "                for i in range(len(high_pre)): WrongVolume.append(high_pre[i])\n",
    "                for i in range(len(low_pre)): WrongVolume.append(low_pre[i])\n",
    "                for i in range(len(low_close)): WrongVolume.append(low_close[i])\n",
    "                for i in range(len(close_pre)): WrongVolume.append(close_pre[i])\n",
    "                    \n",
    "                for i in range(len(adj_open_low)): WrongVolume.append(adj_open_low[i])\n",
    "                for i in range(len(adj_open_high)): WrongVolume.append(adj_open_high[i])\n",
    "                for i in range(len(adj_open_close)): WrongVolume.append(adj_open_close[i])\n",
    "                for i in range(len(adj_high_low)): WrongVolume.append(adj_high_low[i])\n",
    "                for i in range(len(adj_high_close)): WrongVolume.append(adj_high_close[i])\n",
    "                for i in range(len(adj_low_close)): WrongVolume.append(adj_low_close[i])\n",
    "                \n",
    "                print(str(WrongVolume) + \" does not have equal price/adjprice\")\n",
    "                write_log(self.logger, str(WrongVolume) + \" does not have equal price/adjprice\")\n",
    "        pass    \n",
    "        '''\n",
    "        else:\n",
    "            for sid, data in self.data_df.groupby(level = 'S_INFO_WINDCODE'):\n",
    "                print(sid + \"check volume\")\n",
    "                for i in range(len(data)):\n",
    "                    if(data.iloc[i]['S_VOLUME'] == 0):\n",
    "                        price = data.iloc[i]['S_DQ_OPEN']\n",
    "                        adjprice = data.iloc[i]['S_DQ_ADJOPEN']\n",
    "                        if((data.iloc[i]['S_DQ_LOW'] == price) & (data.iloc[i]['S_DQ_HIGH'] == price) & \n",
    "                           (data.iloc[i]['S_DQ_CLOSE'] == price) & (data.iloc[i]['S_DQ_ADJLOW'] == adjprice) & \n",
    "                           (data.iloc[i]['S_DQ_ADJHIGH'] == adjprice) & (data.iloc[i]['S_DQ_ADJCLOSE'] == adjprice) &\n",
    "                           (data.iloc[i]['S_PCTCHANGE'] == 0)):\n",
    "                            pass\n",
    "                        else:\n",
    "                            print(str(data.index[i]) + \" does not have equal price/adjprice\")\n",
    "                            write_log(self.logger, str(data.index[i]) + \" does not have equal price/adjprice\")\n",
    "        \n",
    "        pass\n",
    "        '''\n",
    "    \n",
    "    def list_ret_dist(self,lower_bound=-0.1,upper_bound=0.1):\n",
    "        '''\n",
    "        list the return of which sid out of the bound\n",
    "        '''\n",
    "        if(self.data_df.empty == True):\n",
    "            pass\n",
    "        else:\n",
    "            print(\"check list ret dist\")\n",
    "            upper = self.data_df.loc[self.data_df['S_PCTCHANGE'] >= upper_bound * 100,].index\n",
    "            lower = self.data_df.loc[self.data_df['S_PCTCHANGE'] <= lower_bound * 100,].index\n",
    "            \n",
    "            if((len(upper) + len(lower)) > 0):\n",
    "                LimitPrice = []\n",
    "                for i in range(len(upper)): LimitPrice.append(upper[i])\n",
    "                for i in range(len(lower)): LimitPrice.append(lower[i])\n",
    "                    \n",
    "                print(str(LimitPrice) + \" have reach upper bound or lower bound\")\n",
    "                write_log(self.logger, str(LimitPrice) + \" have reach upper bound or lower bound\")\n",
    "        pass\n",
    "        '''\n",
    "        else:\n",
    "            for sid, data in self.data_df.groupby(level = 'S_INFO_WINDCODE'):\n",
    "                print(sid + \"check list ret dist\")\n",
    "                for i in range(len(data)):\n",
    "                    if((data.iloc[i]['S_PCTCHANGE'] >= upper_bound * 100) | (data.iloc[i]['S_PCTCHANGE'] <= lower_bound * 100)):\n",
    "                        print(str(data.index[i]) + \" have reach upper bound or lower bound\")\n",
    "                        write_log(self.logger, str(data.index[i]) + \" have reach upper bound or lower bound\")\n",
    "        pass\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def list_st_change(self):\n",
    "        '''\n",
    "        which become ST or become non-ST\n",
    "        '''\n",
    "        if(self.data_df.empty == True):\n",
    "            pass\n",
    "        else:\n",
    "            for sid, data in self.data_df.groupby(level = 'S_INFO_WINDCODE'):\n",
    "                print(sid + \"check list st change\")\n",
    "                for i in range(len(data)):\n",
    "                    if((data.iloc[i -1]['ST_FLAG'] == 0) & (data.iloc[i]['ST_FLAG'] == 1) & (i > 0)):\n",
    "                        print(str(data.index[i]) + \" from non-ST stock become ST stock\")\n",
    "                        write_log(self.logger, str(data.index[i]) + \" from non-ST stock become ST stock\")\n",
    "                    elif((data.iloc[i - 1]['ST_FLAG'] == 1) & (data.iloc[i]['ST_FLAG'] == 0) & (i > 0)):\n",
    "                        print(str(data.index[i]) + \" from ST stock become non-ST stock\")\n",
    "                        write_log(self.logger, str(data.index[i]) + \" from ST stock become non-ST stock\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-47fb159a2bbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#print([i for i in split_date(20061101)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#print([i for i in split_date(20181228)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     date_list = [str((datetime.today() - timedelta(days = 30)).strftime('%Y%m%d')), \n\u001b[0m\u001b[0;32m      5\u001b[0m                  str(datetime.today().strftime('%Y%m%d'))]\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#date_list = [20180901, 20190101]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #print([i for i in split_date(20061101)])\n",
    "    #print([i for i in split_date(20181228)])\n",
    "    date_list = [str((datetime.today() - timedelta(days = 30)).strftime('%Y%m%d')), \n",
    "                 str(datetime.today().strftime('%Y%m%d'))]\n",
    "    #date_list = [20180901, 20190101]\n",
    "    for i in range(len(date_list)-1):\n",
    "        start = datetime.now()\n",
    "        df = get_SuperTable(date_list[i], date_list[i+1])\n",
    "        df = df.set_index(['S_INFO_WINDCODE', 'TRADE_DT'])\n",
    "        print(\"读取数据时间： \" + str(datetime.now() - start))\n",
    "        df_DataDate = get_DataDate(date_list[i], date_list[i+1])\n",
    "        logger_file = 'log' + str(date_list[i]) + '-' + str(date_list[i+1]) + '_Follower'\n",
    "        wind_logger = set_logger(log_file=logger_file)\n",
    "        wind_logger.info(\"This is a test\")\n",
    "        wind_logger.debug(\"This is a test\")\n",
    "        a = datachecking(df, df_stock_info, df_DataDate, wind_logger, 20191201, str(datetime.today().strftime('%Y%m%d')))\n",
    "        start = datetime.now()\n",
    "        a.check_abvalue()\n",
    "        a.check_datadate()\n",
    "        #a.check_idx_unique()\n",
    "        a.check_listed_range()\n",
    "        a.check_sid_tidx()\n",
    "        a.check_price()\n",
    "        a.check_volume()\n",
    "        a.list_ret_dist()\n",
    "        a.list_st_change()\n",
    "        print(\"筛查数据所需时间： \" + str(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
